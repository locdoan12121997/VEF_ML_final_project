{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_metric(y_actual, y_predicted):\n",
    "    y_actual_log = np.log(y_actual + 1)\n",
    "    y_predicted_log = np.log(y_predicted + 1)\n",
    "    rms = sqrt(mean_squared_error(y_actual_log, y_predicted_log))\n",
    "    return rms\n",
    "\n",
    "def rmse(y_act,y_pred):\n",
    "    rms=sqrt(mean_squared_error(y_act,y_pred))\n",
    "    return rms\n",
    "def loss(x):\n",
    "    return np.sum(np.square((np.dot(x, m) - y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = pd.read_csv('Data/train_data_hhp.csv')\n",
    "Xtest = pd.read_csv('Data/test_data_hhp.csv')\n",
    "\n",
    "Ytrain=Xtrain['DaysInHospital']\n",
    "Ytest=Xtest['DaysInHospital']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input partial output from XGB , RandomForest (classifier and regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regressor XGB _scaled\n",
    "Y2_pred_XGBregr_Scaled = pd.read_csv('Data/Y2_pred_XGBregr_scaled.csv')\n",
    "Y3_pred_XGBregr_Scaled = pd.read_csv('Data/Y3_pred_XGBregr_scaled.csv')\n",
    "#Regressor XGB _ notscaled\n",
    "Y2_pred_XGBregr_notScaled = pd.read_csv('Data/Y2_pred_XGBregr_notScaled.csv')\n",
    "Y3_pred_XGBregr_notScaled = pd.read_csv('Data/Y3_pred_XGBregr_notScaled.csv')\n",
    "\n",
    "Y2_pred_XGBregr_Scaled.drop(['Unnamed: 0'],axis=1, inplace=True)\n",
    "Y3_pred_XGBregr_Scaled.drop(['Unnamed: 0'],axis=1, inplace=True)\n",
    "Y2_pred_XGBregr_notScaled.drop(['Unnamed: 0'],axis=1, inplace=True)\n",
    "Y3_pred_XGBregr_notScaled.drop(['Unnamed: 0'],axis=1, inplace=True)\n",
    "\n",
    "#Regressor RF _scaled\n",
    "Y2_pred_RFregr_Scaled = pd.read_csv('Data/Y2_pred_RFregr_scaled.csv')\n",
    "Y3_pred_RFregr_Scaled = pd.read_csv('Data/Y3_pred_RFregr_scaled.csv')\n",
    "#Regressor RF _ notscaled\n",
    "Y2_pred_RFregr_notScaled = pd.read_csv('Data/Y2_pred_RFregr_notScaled.csv')\n",
    "Y3_pred_RFregr_notScaled = pd.read_csv('Data/Y3_pred_RFregr_notScaled.csv')\n",
    "\n",
    "\n",
    "Y3_pred_RFregr_Scaled.drop(['Unnamed: 0'],axis=1, inplace=True)\n",
    "Y2_pred_RFregr_Scaled.drop(['Unnamed: 0'],axis=1, inplace=True)\n",
    "Y3_pred_RFregr_notScaled.drop(['Unnamed: 0'],axis=1, inplace=True)\n",
    "Y2_pred_RFregr_notScaled.drop(['Unnamed: 0'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regressor LGBM _scaled1\n",
    "Y2_pred_LGBMregr_Scaled1 = pd.read_csv('Data/Y2_pred_LGBM_scaled1.csv')\n",
    "Y3_pred_LGBMregr_Scaled1 = pd.read_csv('Data/Y3_pred_LGBM_scaled1.csv')\n",
    "Y2_pred_LGBMregr_Scaled1.drop(['Unnamed: 0'],axis=1, inplace=True)\n",
    "Y3_pred_LGBMregr_Scaled1.drop(['Unnamed: 0'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logYtrain=np.log(Ytrain+1)\n",
    "logYtest=np.log(Ytest+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the candidates -  Random Forest (regressor and classifier), XGB (regressor and classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.concat([Y2_pred_LGBMregr_Scaled1, \n",
    "                 Y2_pred_RFregr_Scaled, \n",
    "                 Y2_pred_RFregr_notScaled,\n",
    "                 Y2_pred_XGBregr_Scaled,\n",
    "                Y2_pred_XGBregr_notScaled\n",
    "                ], axis=1)\n",
    "\n",
    "test= pd.concat([Y3_pred_LGBMregr_Scaled1, \n",
    "                 Y3_pred_RFregr_Scaled, \n",
    "                Y3_pred_RFregr_notScaled,\n",
    "                 Y3_pred_XGBregr_Scaled, \n",
    "                Y3_pred_XGBregr_notScaled\n",
    "                ], axis=1)\n",
    "train=np.log(train+1)\n",
    "test=np.log(test+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBregressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGregr = XGBRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble on log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGregr.fit(train, logYtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSME on traing set 0.2715083233007804 RSME on testing set 0.4746792579453372\n"
     ]
    }
   ],
   "source": [
    "logY_pred_test = XGregr .predict(test)\n",
    "logY_pred_train = XGregr .predict(train)\n",
    "\n",
    "print('RSME on traing set',rmse(logYtrain, logY_pred_train),\n",
    "        'RSME on testing set',rmse(logYtest, logY_pred_test),\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regresion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble on log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSME on traing set 0.28042987581259277 RSME on testing set 0.4779778154351217\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(train, logYtrain)\n",
    "logY_pred_test = reg.predict(test)\n",
    "logY_pred_train = reg .predict(train)\n",
    "\n",
    "print('RSME on traing set',rmse(logYtrain, logY_pred_train),\n",
    "        'RSME on testing set',rmse(logYtest, logY_pred_test)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression (on log scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSME on traing set 0.28042987581259277 RSME on testing set 0.4779778154351217\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(train, logYtrain)\n",
    "logY_pred_test = reg.predict(test)\n",
    "logY_pred_train = reg .predict(train)\n",
    "\n",
    "print('RSME on traing set',rmse(logYtrain, logY_pred_train),\n",
    "        'RSME on testing set',rmse(logYtest, logY_pred_test)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stacking(model,train,y,test,n_fold):\n",
    "   folds=StratifiedKFold(n_splits=n_fold,random_state=1)\n",
    "   test_pred=np.empty((test.shape[0],1),float)\n",
    "   train_pred=np.empty((0,1),float)\n",
    "   for train_indices,val_indices in folds.split(train,y.values):\n",
    "      x_train,x_val=train.iloc[train_indices],train.iloc[val_indices]\n",
    "      y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]\n",
    "\n",
    "      model.fit(X=x_train,y=y_train)\n",
    "      train_pred=np.append(train_pred,model.predict(x_val))\n",
    "      test_pred=np.append(test_pred,model.predict(test))\n",
    "    return test_pred.reshape(-1,1),train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinatoric candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive directional derivative for linesearch    (Exit mode 8)\n",
      "            Current function value: 6940.832886089734\n",
      "            Iterations: 10\n",
      "            Function evaluations: 52\n",
      "            Gradient evaluations: 6\n",
      "weight [0.00000000e+00 8.12696322e-01 1.87313257e-01 5.53624935e-07\n",
      " 6.17110627e-07]\n",
      "RSMLE on traing set 0.18303287657454095 RSMLE on testing set 0.29120926614744774\n"
     ]
    }
   ],
   "source": [
    "x_train=(train.values).T\n",
    "x_test=(test.values).T\n",
    "y_train=(logYtrain.values).T\n",
    "y_test=(logYtest.values).T\n",
    "\n",
    "m =x_train\n",
    "y = y_train\n",
    "\n",
    "from scipy.optimize import minimize, rosen, rosen_der\n",
    "\n",
    "cons = ({'type': 'eq',\n",
    "         'fun' : lambda x: np.sum(x) - 1.0})\n",
    "\n",
    "x0 = np.zeros(m.shape[0])\n",
    "res = minimize(loss, x0, method='SLSQP', constraints=cons,\n",
    "               bounds=[(0, np.inf) for i in range(m.shape[0])], options={'disp': True})\n",
    "\n",
    "print('weight',res.x)\n",
    "Y_pred_test=(res.x*x_test.T).sum(axis=1)\n",
    "Y_pred_train=(res.x*x_train.T) .sum(axis=1)\n",
    "print('RSMLE on traing set',count_metric(y_train.T, Y_pred_train.T),\n",
    "        'RSMLE on testing set',count_metric(y_test.T, Y_pred_test.T),\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
